akf xyz 有局限性
主从复制  ha
单节点 容量问题
一下有四种方式
1.数据可以分类，交集不多------clent-----------------》逻辑：业务划分------------------------》redis1，redis2
2.数据没办法划分拆解------client----------------》算法拆分： hash+取模 modula------------------------》redis1，redis2   sharding 分片
缺点：模数值固定 %3 %4 %10 影响分布式下的扩展性
3.数据没办法划分拆解------client----------------》算法拆分： random------------------------》redis1，redis2   sharding 分片--------client
这个可以作为一个消息队列来使用 client端用lpush放入redis里面随机存入ooxx的key之后，lpush-----》另一端用client连接所有的redis用rpop取出
ooxx：topic&partition   kafka
4.数据没办法划分拆解------client----------------》算法拆分： kemata 一致性哈希 没有取模 （key（data），（node承载数据的节点））都需要参与计算
---形成一个规则一个环形2哈希环----虚拟节点（也就是物理点ip或者其他计算值本来只有一个经过hash之后的点在环上，但是我人为的多计算几个ip或者其他计算值+1-9
的值经过hash放在环上这个时候环上就有多个点这样就可以解决数据倾斜问题）------------------------》redis1，redis2   sharding 分片
算法有hash crc16 crc32 fnv md5 映射算法
比如 node1 node2的ip参与hash运算放入环形上两个点上   这个时候data或者key也经过hash运算放在环形hash上对应一个点，这个环是虚拟的，但是环上有node的点
就是物理点  这个时候key或者data计算出来的这个点位置就去找靠近他最近的那个物理点上门进行存储   
优点：你加节点的确可以分担其他节点的压力，不会造成全局洗牌
缺点：新增一个节点会造成一小部分数据不能命中 1.问题 击穿 压到mysql 2.方案，每次取离我最近的两个物理节点

更倾向于作为缓存，而不是数据库用！！！！
                                             redis连接成本很高  对server端造成的
假如 我四个client客户端 -----------都可能访问这个两个redis-----------  reids01  reids02两个
我四个client客户端 -----------hold住连接 反向代理（关注代理层性能）-----------  reids01  reids02两个
                                  代理层：逻辑实现--modula，random，kemata----------无状态-----------》因为有了无状态才能实现反向代理Proxy可以
                                  随意的增加一个，一个坏了，另一个可以直接启动起来
无论你企业后面技术多复杂，对于客户端都是透明的
我四个client客户端 -----VIP《===LVS hold住流量（keepalive 进行主备切换HA）------hold住连接 反向代理（关注代理层性能）-----------  reids01  reids02两个
                       keepalive 还可以间接监控proxy反向代理的健康状况，当有一台坏了的时候，就把所有的流量执行另外一台好的代理

数据分治之后 分布式锁很难实现 也就是聚合操作很难实现 事物
三种
twemproxy  predixy 代理方式实现数据分治 Cluster redis集群实现数据分治
