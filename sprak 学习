MapReduce 复习
   访问数据节点需要通过HDFS访问，如果想发生计算，需要先启动一个client独立的进程-------》通过资源层 yarn---------孵化出两个mapTask先通过hdfs然后
   各种访问自己该访问的具体的那个数据块--------最后map计算完成之后可能会汇聚到一个reduce task里面（可以为多个，这个我们暂时理解为一个）
术语
   client启动之后，第一个术语 application-------后续会产生maptask可能多个 reducetask 可能多个（stage步骤阶段 map-stage  reduce-stage）
   ---有一系列并行的task（maptask reducetask）-----其实他们都是由job启动之后产生的
比列
  一个application---1个job
  一个job----1-2个stage（map reduce 有可能没用reduce）
  一个stafe----n个task（map reduce reduce是可以人为干预的，map是n个）
  多个mr的job可以组成作业链
  
  复用资源 spark就是实现了这个模型的
   一个application---n个job
  一个job----n个stage
  一个stafe----n个task（map reduce reduce是可以人为干预的，map是n个）
  
  mapTask有三个环节  1.输入环节 input-----textinputformat---可以确定你1.client中可以计算切片的数量，也就是计算map的数量2.maptask中
  linerecordreader行记录读取器-------计算完成之后会调用我们重写那个map的方法进行传参，然后最终数据一条一条传递给map
  map计算完成之后再输出，在maptask框架中把map输出的数据收集到outputFile当中，它是保存到本地的
  
  map中我们可以做什么事情，过滤filter，（类似与scalar中的map隐射，flatmap也即是数据的切分，隐射成键值对）-----周老师说的关着门的一句话（
  mapreduce不友好，需要人实现数据迭代逻辑）------------spark就是实现直接数据迭代的方法，我们只需要传递给他一个任务就可以
  
  面向数据集有两个逻辑1.我们怎么取迭代 迭代逻辑  2.业务逻辑
  
  reducetask中有输入环节---输入之后有reduce方法 （ reducebyKey 通过相同的key为一组，这一组数据调用一次reduce方法）也就是reduce方法被调用的时候
  只能是相同的key的数据调用它reduce方法一次，让这批数据在reduce方法中迭代，且这一过程其实使用就是一个嵌套迭代器，前边的输入阶段可以对数据源封装出
  一个迭代器，reduce方法里面在封装一个迭代器，且他们是一个嵌套的关系，-----计算完成之后输出到hdfs作为记录文件
  
  如果你有一个笔记本，听歌，上网，打游戏---如果你用的是mapreduce来做这三件事，他是怎么做的，就是先开笔记本，然后听歌，关机---开机 上网 关机
  --开机 打游戏  关机   偏向于冷启动   如果再中间加了个shuffle对数据进行传递，拉取
  比如 输入----task----输出  
  输入-----task----shuffle-write 去取数据源可以衔接 给另一个task  shuffle-read------task---shuffle-write shuffle-read----task----输出到本机
  或者hdfs或者hbase  最后没有输出的话，前面的操作都是没有意义的，因为他最后没有输出，前面的那些操作如果是在spark里面就是不会执行的，因为最后
  你没有告诉它最后应该干嘛
  -------------------------------------
  一个stage一个阶段以及这个阶段里的task描述的是可以在一台机器顺滑的完成的所有计算---比如在stage0中读取文件记录然后切分中单词，然后再拿出一个
  单词拼接成单词1这个事情是不需要出这台主机的，也就是说如果是分布式情况下你计算一个块的时候，你不需要别的块把数据拉取过来的，他是可以在一台计算
  机面向一条记录完成的事情
  
  spark中RDD这个数据是可以复用的 每一个RDD都有一个唯一的id 以及在运行job的时候每个stage都会有stage id 然后如果另外一个job在运行的时候复用了
  一个stage或者RDD的时候，那么只要这个stage或者RDD只要存在或者说参与了之前的计算了，已经有缓存了，那么这个时候就直接可以复用了
  
  使用编程模型------面向数据集的操作--RDD 抽象类 弹性的分布式数据集---子类
                                                一系列的分区，切片  mapreduce里面的maptask是面向切片的，一个文件有10个切片他就有10个maotask
                                                 reduce的时候会有分区，一个reduce对应一个分区，一个分区里面可以有若干组，一个组只能进入一个
                                                 分区里面 
                                                 
                                                 一个函数是作用在每一个切片，分区上的每一条记录上的
                                                 
                                                 一系列的依赖关系也就是说一个RDD可能是依赖多个其他的RDD合并的
                                                 
                                                 一个分区器作用在键值对的数据集RDD上 可选的
                                                 
                                                 数据本地化计算的概念 也就是说支持计算向数据移动的         可选的
                  -----------------------------------spark worldcount源码解析-------------------------------------------                               
   RDD计算源码解析
      SprakContext 中的 textFile方法中转换第一个RDD的 参数 文件路径 最小分区数也就是我想要分区的数注意是我想要的，并不是一定的 也即是说
      你传入的文件路径可以得到你的块多少个 最后会和你最小分区数做个比较取最大值  如果你计算的文件是分布式系统的文件，他有10个block块，
      这个时候你传入的最新分区数 如果是12 这个时候取12个分区数 ，如果是6 ，这个是去10个  总结就是---并行度最高优先---默认是块
      
      hadoopFile方法 参数 文件路径 
                          输入格式化class textinputformat 两个功能：1,可以算出这个数据有多少个切片 2.可以拿到对每个切片的输入格式化类 记录
                          读取器 recountread
                          读取的键值对类型 longwriteable
                          text
                          最小分区数
      hadoopRDD   解决文件数据输入的
                  第一个RDD 中 继承RDD的 初始化的时候传入了SparkContext和一个nil空值，为什么是空值，因为这个RDD是第一个并没有依赖的其他RDD
                  getpartitions方法 可以得到数据里面就是这个RDD的所有分区
                                    getinputformat方法得到一个输入格式化类 fileinputformat类
                                          getsplit方法 得到多少个切片 面向hadoop文件操作的时候分区应该就是切片这个维度，partition==split
                                             1.得到文件数组
                                             2.在文件数组中，对每一个文件进行一系列操作，拿到文件路径 大小 块的大小 其中还有一个goalsize 
                                             期望的切片大小  最后切片大小是通过 方法算出的 里面就是比较这个期望切片大小和默认块的大小
                                             默认就是 切片的大小就是等于块的大小
                                             3.
                                             
                                    
      
                                                 
                                                 
                                                 
  
  
    
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
